<problem>
<p><br/>
<br/>
The t-test, invented in 1908 by William Sealy Gosset (whose pen-name was "Student") is one of the most commonly used statistical tests.<br/>
The basic premise of the test is that we have two populations and we wish to know whether there is a significant difference between their means. For example, we would like to know whether kids that drink at least one glass of milk each day are significantly taller than their peers. The null hypothesis is that the means of both populations are the same.<br/>
The two populations are assumed to be normally distributed. Or, invoking the central limit theorm, they are assumed to be the sum or mean of a large number of IID random variables.<br/>
There are many variants of the t-test. We list some of the most popular.<br/>
1. <b>One sample t-test:</b> We assume that we know the mean of one population and that we have a sample from the other population. Note that this is still different from the Z-test, because we do not a-priori know the variance of the sampled population.<br/>
2. <b>Two sample t-test, Pooled std:</b> We have samples from both populations, and we assume that their variances are equal. Therefor we can pool both samples to estimate the variance.<br/>
3. <b>Two sample t-test, un-Pooled std:</b> As in 2. but we don't assume that variances of the two populations are equal.<br/>
4. <b>Paired t-test:</b> Suppose we want to show that coffee effects the speed with which people can perform calculations. We can test each person before and after drinking coffee and compare the two performances. In this situation we can "pair" the measurements, which here simply means take their difference. The test we then perform is a one-sample t-test in which the null hypothesis is that the mean is zero. We could, of course, use the same samples to perform a two-sample t-test, however, this would be a <b>weaker</b> test, i.e. it will have a higher probability of making a type II error (fail to reject the null hypothesis) for the same probability of making a type I error.<br/>
----<br/>
Suppose we want people to stay on our web page as long as possible,
measure time between first and last click-on-site.
</p>
  
  
<p>We have two alternatives layouts of the web pages A/B and want to decide which keeps the user on our web site for a longer time. To avoid confusing the user with constantly changing design, we use the same layout to the web pages presented to each user whenever they visit the site. which hypothesis test should we use?</p>
<multiplechoiceresponse>
  <choicegroup type="MultipleChoice">
    <choice correct="false">1-sided z-value</choice>
    <choice correct="false">One sample t-test</choice>
    <choice correct="true">two sample t-test, pooled variance</choice>
    <choice correct="false">paired t-test</choice>
  </choicegroup>
</multiplechoiceresponse>

<p>     </p>
<p>If we show both layouts to the same user upon his different visits, which hypothesis test should we use?</p>
<multiplechoiceresponse>
  <choicegroup type="MultipleChoice">
    <choice correct="false">1-sided z-value</choice>
    <choice correct="false">One sample t-test</choice>
    <choice correct="true">two sample t-test, pooled variance</choice>
    <choice correct="false">paired t-test</choice>
  </choicegroup>
</multiplechoiceresponse>

<p>     </p>
<p>Which testing will better help us identify the superior layout? Consider the following scenario. Suppose layout B is generally more attractive than layout A. User John and user Peter both visited the website twice, and are presented with both layouts. With layout B, John's visit time increases from 60 seconds to 61 seconds, and Peter's visit time increases from 90 seconds to 91 seconds. The variance of the <b> sample difference of average time </b> is higher than the variance of the <b> sample average of difference </b>. Different users have varied behavior, but the trend is more clear if we focus on the change of each individual. Pairing data can factor out variations from one user to the next. In other words, compared to two sample t-test, paired t-test</p>
<multiplechoiceresponse>
  <choicegroup type="MultipleChoice">
    <choice correct="true">lowers probability of Type II error, for the same probability of Type I error</choice>
    <choice correct="false">lowers probability of Type I error, for the same probability of Type II error</choice>
    <choice correct="false">does not help. Both types of error still have the same probability</choice>
  </choicegroup>
</multiplechoiceresponse>


</problem>